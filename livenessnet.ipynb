{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the initial learning rate, batch size, and number of\n",
    "# epochs to train for\n",
    "INIT_LR = 1e-4\n",
    "BS = 8\n",
    "EPOCHS = 50\n",
    "\n",
    "imagePaths = list(paths.list_images(\"ROI\"))\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over all image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename, load the image and\n",
    "\t# resize it to be a fixed 32x32 pixels, ignoring aspect ratio\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.resize(image, (32, 32))\n",
    "\t# update the data and labels lists, respectively\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels (which are currently strings) as integers and then\n",
    "# one-hot encode them\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = to_categorical(labels, 2)\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "\ttest_size=0.25, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LivenessNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "            # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(16, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "\t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\tmodel.add(Dropout(0.25))\n",
    "        # first (and only) set of FC => RELU layers\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(64))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Dropout(0.5))\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maliciousbrew/.local/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n",
      "2022-06-08 21:12:39.324661: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:40.029875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:40.030663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:40.060347: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-08 21:12:40.069070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:40.069859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:40.070502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:45.028330: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:45.028721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:45.029004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-08 21:12:45.029207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3359 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network for 50 epochs...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-08 21:12:56.630000: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127/127 [==============================] - 23s 12ms/step - loss: 0.7585 - accuracy: 0.6999 - val_loss: 0.7496 - val_accuracy: 0.3196\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 1s 8ms/step - loss: 0.5506 - accuracy: 0.8124 - val_loss: 0.5494 - val_accuracy: 0.8152\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.4557 - accuracy: 0.8460 - val_loss: 0.3529 - val_accuracy: 0.9824\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.8490 - val_loss: 0.2463 - val_accuracy: 0.9853\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.3843 - accuracy: 0.8697 - val_loss: 0.2004 - val_accuracy: 0.9883\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.3178 - accuracy: 0.9042 - val_loss: 0.1531 - val_accuracy: 0.9883\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2960 - accuracy: 0.9121 - val_loss: 0.1681 - val_accuracy: 0.9941\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2636 - accuracy: 0.9260 - val_loss: 0.1339 - val_accuracy: 0.9912\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.2378 - accuracy: 0.9398 - val_loss: 0.1094 - val_accuracy: 0.9912\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2453 - accuracy: 0.9319 - val_loss: 0.0940 - val_accuracy: 0.9912\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2592 - accuracy: 0.9240 - val_loss: 0.0908 - val_accuracy: 0.9912\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2134 - accuracy: 0.9418 - val_loss: 0.0760 - val_accuracy: 0.9912\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2229 - accuracy: 0.9368 - val_loss: 0.0848 - val_accuracy: 0.9912\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9447 - val_loss: 0.0869 - val_accuracy: 0.9912\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2002 - accuracy: 0.9378 - val_loss: 0.0952 - val_accuracy: 0.9941\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.9585 - val_loss: 0.0764 - val_accuracy: 0.9912\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.2161 - accuracy: 0.9358 - val_loss: 0.0912 - val_accuracy: 0.9941\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1922 - accuracy: 0.9487 - val_loss: 0.1057 - val_accuracy: 0.9941\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1599 - accuracy: 0.9546 - val_loss: 0.0611 - val_accuracy: 0.9941\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1584 - accuracy: 0.9585 - val_loss: 0.0480 - val_accuracy: 0.9941\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 1s 7ms/step - loss: 0.1464 - accuracy: 0.9556 - val_loss: 0.0421 - val_accuracy: 0.9971\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1509 - accuracy: 0.9566 - val_loss: 0.0448 - val_accuracy: 0.9971\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1548 - accuracy: 0.9536 - val_loss: 0.0505 - val_accuracy: 0.9971\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1662 - accuracy: 0.9546 - val_loss: 0.0385 - val_accuracy: 0.9941\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1360 - accuracy: 0.9654 - val_loss: 0.0313 - val_accuracy: 0.9941\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1608 - accuracy: 0.9585 - val_loss: 0.0420 - val_accuracy: 0.9971\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1800 - accuracy: 0.9467 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1364 - accuracy: 0.9566 - val_loss: 0.0310 - val_accuracy: 0.9971\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1544 - accuracy: 0.9506 - val_loss: 0.0333 - val_accuracy: 0.9971\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1330 - accuracy: 0.9556 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1151 - accuracy: 0.9615 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1447 - accuracy: 0.9477 - val_loss: 0.0367 - val_accuracy: 0.9971\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1346 - accuracy: 0.9556 - val_loss: 0.0277 - val_accuracy: 0.9971\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1257 - accuracy: 0.9625 - val_loss: 0.0305 - val_accuracy: 0.9971\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1364 - accuracy: 0.9576 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1474 - accuracy: 0.9487 - val_loss: 0.0294 - val_accuracy: 0.9971\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1069 - accuracy: 0.9645 - val_loss: 0.0211 - val_accuracy: 0.9971\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1084 - accuracy: 0.9684 - val_loss: 0.0800 - val_accuracy: 0.9971\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0986 - accuracy: 0.9743 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1127 - accuracy: 0.9615 - val_loss: 0.0251 - val_accuracy: 0.9971\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.0913 - accuracy: 0.9684 - val_loss: 0.0205 - val_accuracy: 0.9971\n",
      "Epoch 42/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0998 - accuracy: 0.9733 - val_loss: 0.0207 - val_accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.9635 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0948 - accuracy: 0.9694 - val_loss: 0.0209 - val_accuracy: 0.9971\n",
      "Epoch 45/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.0979 - accuracy: 0.9694 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0997 - accuracy: 0.9664 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "127/127 [==============================] - 1s 5ms/step - loss: 0.1110 - accuracy: 0.9566 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.1176 - accuracy: 0.9605 - val_loss: 0.0137 - val_accuracy: 0.9971\n",
      "Epoch 49/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0944 - accuracy: 0.9733 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "127/127 [==============================] - 1s 6ms/step - loss: 0.0883 - accuracy: 0.9753 - val_loss: 0.0175 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Keras TensorBoard callbacks\n",
    "from datetime import datetime\n",
    "import keras\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
    "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = LivenessNet.build(width=32, height=32, depth=3,\n",
    "\tclasses=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit(x=aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), \n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS,\n",
    "\tcallbacks=[tensorboard_callback])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "43/43 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       1.00      1.00      1.00        86\n",
      "        Real       1.00      1.00      1.00       255\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n",
      "[INFO] serializing network to 'models/'...\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(x=testX, batch_size=BS)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=le.classes_))\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format(\"models/\"))\n",
    "model.save(\"models/model4\", save_format=\"h5\")\n",
    "# save the label encoder to disk\n",
    "f = open(\"labelEncoder/le4\", \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plots/plot2\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
